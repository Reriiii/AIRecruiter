import chromadb
import uuid
import json
import os
from typing import Dict, List, Optional
from datetime import datetime

def normalize_metadata(metadata: dict):
    fixed = {}

    for k, v in metadata.items():
        if isinstance(v, list):
            fixed[k] = ", ".join(map(str, v))  
        elif isinstance(v, dict):
            fixed[k] = json.dumps(v, ensure_ascii=False)  
        elif v is None:
            fixed[k] = ""
        else:
            fixed[k] = v

    return fixed

class VectorStore:
    """
    Quáº£n lÃ½ Vector Database (ChromaDB) Ä‘á»ƒ lÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m á»©ng viÃªn
    """
    
    def __init__(self, db_path: str = "./data/chroma_db"):
        """
        Khá»Ÿi táº¡o Vector Store
        
        Args:
            db_path: ÄÆ°á»ng dáº«n lÆ°u trá»¯ database
        """
        print(f"ðŸ’¾ Äang khá»Ÿi táº¡o Vector Database táº¡i: {db_path}")
        
        try:
            self.client = chromadb.PersistentClient(path=db_path)
            
            self.collection = self.client.get_or_create_collection(
                name="candidates",
                metadata={"hnsw:space": "cosine"} 
            )
            
            print(f"âœ… Vector Database sáºµn sÃ ng. Sá»‘ lÆ°á»£ng á»©ng viÃªn: {self.collection.count()}")
            
        except Exception as e:
            raise Exception(f"KhÃ´ng thá»ƒ khá»Ÿi táº¡o Vector Database: {e}")

    def save_candidate(
        self, 
        cv_text: str, 
        cv_data: Dict, 
        embedding: List[float],
        file_name: str = ""
    ) -> str:
        """
        LÆ°u thÃ´ng tin á»©ng viÃªn vÃ o database
        
        Args:
            cv_text: Ná»™i dung CV dáº¡ng text (raw)
            cv_data: ThÃ´ng tin Ä‘Ã£ trÃ­ch xuáº¥t (JSON)
            embedding: Vector embedding
            file_name: TÃªn file CV gá»‘c
            
        Returns:
            str: ID cá»§a document Ä‘Ã£ lÆ°u
        """
        doc_id = str(uuid.uuid4())
        metadata = self._prepare_metadata(cv_data, file_name)

        # Try to add to collection but don't let telemetry/add errors fail the whole flow
        add_failed = False
        try:
            self.collection.add(
                ids=[doc_id],
                embeddings=[embedding],
                metadatas=[metadata],
                documents=[cv_text]
            )
            print(f"ÄÃ£ lÆ°u á»©ng viÃªn: {metadata.get('full_name')} (ID: {doc_id[:8]}...)")
        except Exception as e:
            # Some chromadb versions emit telemetry-related exceptions after add;
            # log and continue so the overall upload doesn't return 500 when DB was already written.
            print(f"âš ï¸ Lá»—i khi thÃªm vÃ o collection (khÃ´ng cháº·n): {e}")
            add_failed = True

        # Write full profile to disk (try regardless of add outcome)
        try:
            os.makedirs(os.path.dirname(f"./data/full_profiles/{doc_id}.json"), exist_ok=True)
            with open(f"./data/full_profiles/{doc_id}.json", "w", encoding="utf-8") as f:
                json.dump(cv_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ Lá»—i khi lÆ°u full profile: {e}")

        # If add failed earlier, still return the generated id to avoid upstream 500s.
        return doc_id

    def _prepare_metadata(self, cv_data: Dict, file_name: str = "") -> Dict:
        skills = cv_data.get("skills", [])
        projects = cv_data.get("projects", [])
        education = cv_data.get("education", [])

        gpa_values = [e["gpa"] for e in education if e.get("gpa") is not None]
        project_scores = [p["score"] for p in projects if p.get("score") is not None]

        raw_metadata = {
            "full_name": cv_data.get("full_name", "N/A"),
            "email": cv_data.get("email", "N/A"),
            "role": cv_data.get("role", "N/A"),
            "years_exp": int(cv_data.get("years_exp", 0)),
            "gpa": float(sum(gpa_values) / len(gpa_values)) if gpa_values else 0.0,
            "project_score": float(sum(project_scores) / len(project_scores)) if project_scores else 0.0,
            "skills_list": ", ".join(skills),

            "file_source": file_name,
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

        return normalize_metadata(raw_metadata)

    def search_candidates(
        self, 
        query_embedding: List[float], 
        n_results: int = 10,
        min_exp: int = 0,
        required_skills: Optional[List[str]] = None
    ) -> Dict:
        """
        TÃ¬m kiáº¿m á»©ng viÃªn phÃ¹ há»£p
        
        Args:
            query_embedding: Vector cá»§a Job Description
            n_results: Sá»‘ lÆ°á»£ng káº¿t quáº£ tráº£ vá»
            min_exp: Sá»‘ nÄƒm kinh nghiá»‡m tá»‘i thiá»ƒu
            required_skills: Danh sÃ¡ch ká»¹ nÄƒng báº¯t buá»™c (optional)
            
        Returns:
            Dict: Káº¿t quáº£ tÃ¬m kiáº¿m
        """
        try:
            where_clause = {"years_exp": {"$gte": min_exp}}
            
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results,
                where=where_clause,
                include=["embeddings", "metadatas", "documents", "distances"]
            )
            
            if required_skills and results['ids']:
                filtered_results = self._filter_by_skills(results, required_skills)
                return filtered_results
            
            return results
            
        except Exception as e:
            raise Exception(f"Lá»—i khi tÃ¬m kiáº¿m: {e}")

    def _filter_by_skills(self, results: Dict, required_skills: List[str]) -> Dict:
        """
        Lá»c káº¿t quáº£ theo skills báº¯t buá»™c (post-processing)
        
        Args:
            results: Káº¿t quáº£ tá»« ChromaDB
            required_skills: Danh sÃ¡ch ká»¹ nÄƒng cáº§n cÃ³
            
        Returns:
            Dict: Káº¿t quáº£ Ä‘Ã£ lá»c
        """
        filtered_ids = []
        filtered_metadatas = []
        filtered_documents = []
        filtered_distances = []
        
        for i in range(len(results['ids'][0])):
            candidate_skills = results['metadatas'][0][i].get('skills_list', '').lower()
            
            has_required = all(
                skill.lower() in candidate_skills 
                for skill in required_skills
            )
            
            if has_required:
                filtered_ids.append(results['ids'][0][i])
                filtered_metadatas.append(results['metadatas'][0][i])
                filtered_documents.append(results['documents'][0][i])
                filtered_distances.append(results['distances'][0][i])
        
        return {
            'ids': [filtered_ids],
            'metadatas': [filtered_metadatas],
            'documents': [filtered_documents],
            'distances': [filtered_distances]
        }

    def get_all_candidates(self, limit=100):
        results = self.collection.get(limit=limit, include=["metadatas"])

        full_results = []

        for i, meta in enumerate(results["metadatas"]):
            cid = results["ids"][i]

            profile = {}
            file_path = f"./data/full_profiles/{cid}.json"

            if os.path.exists(file_path):
                with open(file_path, "r", encoding="utf-8") as f:
                    profile = json.load(f)

            full_results.append({
                "id": cid,
                **meta,
                **profile
            })

        return full_results


    def delete_candidate(self, candidate_id: str) -> bool:
        """
        XÃ³a á»©ng viÃªn khá»i DB + xÃ³a file lÆ°u trá»¯

        Args:
            candidate_id: ID cá»§a á»©ng viÃªn
            
        Returns:
            bool: True náº¿u má»i thá»© Ä‘á»u xÃ³a ok
        """
        success = True  
        
        try:
            self.collection.delete(ids=[candidate_id])
            print(f"ÄÃ£ xÃ³a á»©ng viÃªn khá»i DB: {candidate_id[:8]}...")
        except Exception as e:
            print(f"âš ï¸ Lá»—i khi xÃ³a trong DB: {e}")
            success = False

        try:
            json_path = f"./data/full_profiles/{candidate_id}.json"
            if os.path.exists(json_path):
                os.remove(json_path)
                print(f"ÄÃ£ xÃ³a JSON: {json_path}")
            else:
                print(f"KhÃ´ng tÃ¬m tháº¥y JSON: {json_path}")
        except Exception as e:
            print(f"Lá»—i khi xÃ³a JSON: {e}")
            success = False

        try:
            folder = "./data/uploaded_cvs"
            deleted_pdf = False

            for file in os.listdir(folder):
                if candidate_id in file:  # file chá»©a id
                    os.remove(os.path.join(folder, file))
                    print(f"ÄÃ£ xÃ³a PDF: {file}")
                    deleted_pdf = True

            if not deleted_pdf:
                print(f"KhÃ´ng tÃ¬m tháº¥y PDF cá»§a á»©ng viÃªn trong {folder}")
        except Exception as e:
            print(f"âš ï¸ Lá»—i khi xÃ³a PDF: {e}")
            success = False

        return success

    def get_stats(self) -> Dict:
        """
        Láº¥y thá»‘ng kÃª database
        
        Returns:
            Dict: ThÃ´ng tin thá»‘ng kÃª
        """
        try:
            total = self.collection.count()
            return {
                "total_candidates": total,
                "collection_name": self.collection.name
            }
        except Exception as e:
            return {"error": str(e)}